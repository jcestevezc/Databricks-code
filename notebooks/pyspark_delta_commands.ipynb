{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# PySpark and Delta Lake Data Processing"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["This notebook lists common commands for working with data using PySpark and Delta Lake."]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 1. Initialize Spark"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('delta-demo').getOrCreate()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 2. Read Data from CSV"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "df = spark.read.option('header', True).csv('/path/to/input.csv')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 3. Write Data as Delta"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "df.write.format('delta').mode('overwrite').save('/path/to/delta-table')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 4. Read a Delta Table"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "delta_df = spark.read.format('delta').load('/path/to/delta-table')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 5. Transformations"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "result_df = (\n    delta_df.filter(\"status = 'ACTIVE'\")\n            .groupBy('category')\n            .count()\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 6. Save Table to the Metastore"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "result_df.write.format('delta').mode('overwrite').saveAsTable('catalog.schema.output_table')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 7. Upsert (MERGE) Data"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from delta.tables import DeltaTable\n\ndelta_table = DeltaTable.forPath(spark, '/path/to/delta-table')\n\n(delta_table.alias('t')\n .merge(source=result_df.alias('s'), condition='t.id = s.id')\n .whenMatchedUpdateAll()\n .whenNotMatchedInsertAll()\n .execute())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 8. Optimize and Vacuum"]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "spark.sql('OPTIMIZE delta.`/path/to/delta-table`')\n\ndelta_table.vacuum(retentionHours=168)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
