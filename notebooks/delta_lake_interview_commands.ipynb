{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delta Lake Commands for Interviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook summarizes the most common Delta Lake commands you might use in Databricks during an interview. Replace the example paths and table names with your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from pyspark.sql import SparkSession\n\nspark = SparkSession.builder.appName('delta-demo').getOrCreate()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write a DataFrame as Delta"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "df.write.format('delta').mode('overwrite').save('/path/to/delta-table')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read a Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "delta_df = spark.read.format('delta').load('/path/to/delta-table')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Table in the Metastore"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "delta_df.write.format('delta').mode('overwrite').saveAsTable('catalog.schema.table_name')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Merge (Upsert) Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "from delta.tables import DeltaTable\n\ndelta_table = DeltaTable.forPath(spark, '/path/to/delta-table')\n\n(delta_table.alias('t')\n .merge(source=updates_df.alias('s'), condition='t.id = s.id')\n .whenMatchedUpdateAll()\n .whenNotMatchedInsertAll()\n .execute())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Update Rows"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "delta_table.update(condition='id = 1', set={'status': 'closed'})"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Delete Rows"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "delta_table.delete(condition='status = \"obsolete\"')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Time Travel Read"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "old_df = spark.read.format('delta').option('versionAsOf', 0).load('/path/to/delta-table')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Show Table History"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "spark.sql('DESCRIBE HISTORY delta.`/path/to/delta-table`')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Optimize the Table"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "spark.sql('OPTIMIZE delta.`/path/to/delta-table`')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Vacuum Old Files"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "delta_table.vacuum(retentionHours=168)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Convert Existing Parquet to Delta"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "spark.sql('CONVERT TO DELTA parquet.`/path/to/parquet-data`')"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
